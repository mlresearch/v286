---
title: 'Revisiting the Equivalence of Bayesian Neural Networks and Gaussian Processes:
  On the Importance of Learning Activations'
abstract: Gaussian Processes (GPs) provide a convenient framework for specifying function-space
  priors, making them a natural choice for modeling uncertainty. In contrast, Bayesian
  Neural Networks (BNNs) offer greater scalability and extendability but lack the
  advantageous properties of GPs. This motivates the development of BNNs capable of
  replicating GP-like behavior. However, existing solutions are either limited to
  specific GP kernels or rely on heuristics. We demonstrate that trainable activations
  are crucial for effective mapping of GP priors to wide BNNs. Specifically, we leverage
  the closed-form 2-Wasserstein distance for efficient gradient-based optimization
  of reparameterized priors and activations. Beyond learned activations, we also introduce
  trainable periodic activations that ensure global stationarity by design, and functional
  priors conditioned on GP hyperparameters to allow efficient model selection. Empirically,
  our method consistently outperforms existing approaches or matches performance of
  the heuristic methods, while offering stronger theoretical foundations.
software: https://github.com/gmum/bnn-functional-priors
openreview: AligBAsYWE
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sendera25a
month: 0
tex_title: 'Revisiting the Equivalence of Bayesian Neural Networks and Gaussian Processes:
  On the Importance of Learning Activations'
firstpage: 3675
lastpage: 3700
page: 3675-3700
order: 3675
cycles: false
bibtex_author: Sendera, Marcin and Sorkhei, Amin and Ku\'{s}mierczyk, Tomasz
author:
- given: Marcin
  family: Sendera
- given: Amin
  family: Sorkhei
- given: Tomasz
  family: Ku≈õmierczyk
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/sendera25a/sendera25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
