---
title: Adversarial Training May Induce Deteriorating Distributions
abstract: The interactions between the update of model parameters and the update of
  perturbation operators complicate the dynamics of adversarial training (AT). This
  paper reveals a surprising behavior in AT, namely that the distribution induced
  by adversarial perturbations during AT becomes progressively more difficult to learn.
  We derived a generalization bound to theoretically attribute this behavior to the
  increasing of a quantity associated with the perturbation operator, namely, its
  local dispersion. We corroborate this explanation with concrete experimental validations
  and show that this deteriorating behavior of the induced distributions is correlated
  with robust overfitting of AT.
openreview: 8ixaK3sMhv
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tian25b
month: 0
tex_title: Adversarial Training May Induce Deteriorating Distributions
firstpage: 4185
lastpage: 4203
page: 4185-4203
order: 4185
cycles: false
bibtex_author: Tian, Runzhi and Mao, Yongyi
author:
- given: Runzhi
  family: Tian
- given: Yongyi
  family: Mao
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/tian25b/tian25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
