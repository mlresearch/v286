---
title: Evasion Attacks Against Bayesian Predictive Models
abstract: 'There is an increasing interest in analyzing the behavior of machine learning
  systems against adversarial attacks. However, most of the research in adversarial
  machine learning has focused on studying weaknesses against evasion or poisoning
  attacks to predictive models in classical setups, with the susceptibility of Bayesian
  predictive models to attacks remaining underexplored. This paper introduces a general
  methodology for designing optimal evasion attacks against such models. We investigate
  two adversarial objectives: perturbing specific point predictions and altering the
  entire posterior predictive distribution. For both scenarios, we propose novel gradient-based
  attacks and study their implementation and properties in various computational setups.'
software: https://github.com/pablogarciarce/AdvReg
openreview: BBM6GWAGDV
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: arce25a
month: 0
tex_title: Evasion Attacks Against Bayesian Predictive Models
firstpage: 184
lastpage: 202
page: 184-202
order: 184
cycles: false
bibtex_author: Arce, Pablo G. and Naveiro, Roi and Insua, David R\'{i}os
author:
- given: Pablo G.
  family: Arce
- given: Roi
  family: Naveiro
- given: David RÃ­os
  family: Insua
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/arce25a/arce25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
