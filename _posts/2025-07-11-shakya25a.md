---
title: Reparameterizing Hybrid Markov Logic Networks to handle Covariate-Shift in
  Representations
abstract: We utilize Hybrid Markov Logic Networks (HMLNs) to combine embeddings learned
  from a Deep Neural Network (DNN) with symbolic relational knowledge. Since a DNN
  may not always learn optimal embeddings, we develop a mixture model to reduce variance
  in the HMLN parameterization. Further, we perform inference in our model that is
  robust to covariate shifts that may occur in the DNN embeddings by reparameterizing
  the HMLN. We evaluate our approach on Graph Neural Networks and show that our approach
  outperforms state-of-the-art methods that combine relational knowledge with DNN
  embeddings when we introduce covariate shifts in the embeddings. Further, we demonstrate
  the utility of our approach in inferring latent student knowledge in a cognitive
  model called Deep Knowledge Tracing.
software: https://github.com/anupshakya07/uquant
openreview: g9t91w6kzC
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shakya25a
month: 0
tex_title: Reparameterizing Hybrid Markov Logic Networks to handle Covariate-Shift
  in Representations
firstpage: 3749
lastpage: 3765
page: 3749-3765
order: 3749
cycles: false
bibtex_author: Shakya, Anup and Magar, Abisha Thapa and Sarkhel, Somdeb and Venugopal,
  Deepak
author:
- given: Anup
  family: Shakya
- given: Abisha Thapa
  family: Magar
- given: Somdeb
  family: Sarkhel
- given: Deepak
  family: Venugopal
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/shakya25a/shakya25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
