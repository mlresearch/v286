---
title: 'STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic
  Multi-Objective Learning'
abstract: Recently, multi-objective optimization (MOO) has gained attention for its
  broad applications in ML, operations research, and engineering. However, MOO algorithm
  design remains in its infancy and many existing MOO methods suffer from unsatisfactory
  convergence rate and sample complexity performance. To address this challenge, in
  this paper, we propose an algorithm called STIMULUS (**st**ochastic path-**i**ntegrated
  **mul**ti-gradient rec**u**rsive e**s**timator), a new and robust approach for solving
  MOO problems. Different from the traditional methods, STIMULUS introduces a simple
  yet powerful recursive framework for updating stochastic gradient estimates to improve
  convergence performance with low sample complexity. In addition, we introduce an
  enhanced version of \algns, termed \algmns, which incorporates a momentum term to
  further expedite convergence. We establish $\mathcal{O}(1/T)$ convergence rates
  of the proposed methods for non-convex settings and $\mathcal{O}(\exp{-\mu T})$
  for strongly convex settings, where $T$ is the total number of iteration rounds.
  Additionally, we achieve the state-of-the-art $O\left(n+\sqrt{n}\epsilon^{-1}\right)$
  sample complexities for non-convex settings and $\mathcal{O}\left(n+ \sqrt{n} \ln
  ({\mu/\epsilon})\right)$ for strongly convex settings, where $\epsilon>0$ is a desired
  stationarity error. Moreover, to alleviate the periodic full gradient evaluation
  requirement in STIMULUS and STIMULUS-M, we further propose enhanced versions with
  adaptive batching called STIMULUS$^+$/ STIMULUS-M$^+$ and provide their theoretical
  analysis.
openreview: iT4xhHsR0F
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu25d
month: 0
tex_title: 'STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic
  Multi-Objective Learning'
firstpage: 2711
lastpage: 2747
page: 2711-2747
order: 2711
cycles: false
bibtex_author: Liu, Zhuqing and Dong, Chaosheng and Momma, Michinari and Shao, Simone
  and Xu, Shaoyuan and Gao, Yan and Yang, Haibo and Liu, Jia
author:
- given: Zhuqing
  family: Liu
- given: Chaosheng
  family: Dong
- given: Michinari
  family: Momma
- given: Simone
  family: Shao
- given: Shaoyuan
  family: Xu
- given: Yan
  family: Gao
- given: Haibo
  family: Yang
- given: Jia
  family: Liu
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/liu25d/liu25d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
