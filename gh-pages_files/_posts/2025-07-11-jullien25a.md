---
title: Distributional Reinforcement Learning with Dual Expectile-Quantile Regression
abstract: Distributional reinforcement learning (RL) has proven useful in multiple
  benchmarks as it enables approximating the full distribution of returns and extracts
  a rich feedback from environment samples. The commonly used quantile regression
  approach to distributional RL – based on asymmetric $L_1$ losses – provides a flexible
  and effective way of learning arbitrary return distributions. In practice, it is
  often improved by using a more efficient, asymmetric hybrid $L_1$-$L_2$ Huber loss
  for quantile regression. However, by doing so, distributional estimation guarantees
  vanish, and we empirically observe that the estimated distribution rapidly collapses
  to its mean. Indeed, asymmetric $L_2$ losses, corresponding to expectile regression,
  cannot be readily used for distributional temporal difference learning. Motivated
  by the efficiency of $L_2$-based learning, we propose to jointly learn expectiles
  and quantiles of the return distribution in a way that allows efficient learning
  while keeping an estimate of the full distribution of returns. We prove that our
  proposed operator converges to the distributional Bellman operator in the limit
  of infinite estimated quantile and expectile fractions, and we benchmark a practical
  implementation on a toy example and at scale. On the Atari benchmark, our approach
  matches the performance of the Huber-based IQN-1 baseline after $200$M training
  frames but avoids distributional collapse and keeps estimates of the full distribution
  of returns.
software: https://github.com/samijullien/ieqn
openreview: 7eOGpSLJa9
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jullien25a
month: 0
tex_title: Distributional Reinforcement Learning with Dual Expectile-Quantile Regression
firstpage: 1909
lastpage: 1923
page: 1909-1923
order: 1909
cycles: false
bibtex_author: Jullien, Sami and Deffayet, Romain and Renders, Jean-Michel and Groth,
  Paul and Rijke, Maarten de
author:
- given: Sami
  family: Jullien
- given: Romain
  family: Deffayet
- given: Jean-Michel
  family: Renders
- given: Paul
  family: Groth
- given: Maarten de
  family: Rijke
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/jullien25a/jullien25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
