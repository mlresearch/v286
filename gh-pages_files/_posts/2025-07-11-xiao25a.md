---
title: The Consistency Hypothesis in Uncertainty Quantification for Large Language
  Models
abstract: Estimating the confidence of large language model (LLM) outputs is essential
  for real-world applications requiring high user trust. Black-box uncertainty quantification
  (UQ) methods, relying solely on model API access, have gained popularity due to
  their practical benefits. In this paper, we examine the implicit assumption behind
  several UQ methods, which use generation consistency as a proxy for confidence-an
  idea we formalize as the consistency hypothesis. We introduce three mathematical
  statements with corresponding statistical tests to capture variations of this hypothesis
  and metrics to evaluate LLM output conformity across tasks. Our empirical investigation,
  spanning 8 benchmark datasets and 3 tasks (question answering, text summarization,
  and text-to-SQL), highlights the prevalence of the hypothesis under different settings.
  Among the statements, we highlight the ‘Sim-Any’ hypothesis as the most actionable,
  and demonstrate how it can be leveraged by proposing data-free black-box UQ methods
  that aggregate similarities between generations for confidence estimation. These
  approaches can outperform the closest baselines, showcasing the practical value
  of the empirically observed consistency hypothesis.
openreview: U7OqtCNU0m
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xiao25a
month: 0
tex_title: The Consistency Hypothesis in Uncertainty Quantification for Large Language
  Models
firstpage: 4636
lastpage: 4651
page: 4636-4651
order: 4636
cycles: false
bibtex_author: Xiao, Quan and Bhattacharjya, Debarun and Ganesan, Balaji and Marinescu,
  Radu and Mirylenka, Katya and Pham, Nhan H and Glass, Michael and Lee, Junkyu
author:
- given: Quan
  family: Xiao
- given: Debarun
  family: Bhattacharjya
- given: Balaji
  family: Ganesan
- given: Radu
  family: Marinescu
- given: Katya
  family: Mirylenka
- given: Nhan H
  family: Pham
- given: Michael
  family: Glass
- given: Junkyu
  family: Lee
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/xiao25a/xiao25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
