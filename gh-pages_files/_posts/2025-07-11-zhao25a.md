---
title: Sample and Computationally Efficient Continuous-Time Reinforcement Learning
  with General Function Approximation
abstract: Continuous-time reinforcement learning (CTRL) provides a principled framework
  for sequential decision-making in environments where interactions evolve continuously
  over time. Despite its empirical success, the theoretical understanding of CTRL
  remains limited, especially in settings with general function approximation. In
  this work, we propose a model-based CTRL algorithm that achieves both sample and
  computational efficiency. Our approach leverages optimism-based confidence sets
  to establish the first sample complexity guarantee for CTRL with general function
  approximation, showing that a near-optimal policy can be learned with a suboptimality
  gap of $\tilde{O}(\sqrt{d_{\mathcal{R}} + d_{\mathcal{F}}}N^{-1/2})$ using $N$ measurements,
  where $d_{\mathcal{R}}$ and $d_{\mathcal{F}}$ denote the distributional Eluder dimensions
  of the reward and dynamic functions, respectively, capturing the complexity of general
  function approximation in reinforcement learning. Moreover, we introduce structured
  policy updates and an alternative measurement strategy that significantly reduce
  the number of policy updates and rollouts while maintaining competitive sample efficiency.
  Our proposed algorithms are validated through experiments on continuous control
  tasks and diffusion model fine-tuning, demonstrating comparable performance with
  significantly fewer policy updates and rollouts.
software: https://github.com/MLIUB/PURE
openreview: JFSZewaXaG
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao25a
month: 0
tex_title: Sample and Computationally Efficient Continuous-Time Reinforcement Learning
  with General Function Approximation
firstpage: 5030
lastpage: 5057
page: 5030-5057
order: 5030
cycles: false
bibtex_author: Zhao, Runze and Yu, Yue and Zhu, Adams Yiyue and Yang, Chen and Zhou,
  Dongruo
author:
- given: Runze
  family: Zhao
- given: Yue
  family: Yu
- given: Adams Yiyue
  family: Zhu
- given: Chen
  family: Yang
- given: Dongruo
  family: Zhou
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/zhao25a/zhao25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
