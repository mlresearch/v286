---
title: Residual Reweighted Conformal Prediction for Graph Neural Networks
abstract: Graph Neural Networks (GNNs) excel at modeling relational data but face
  significant challenges in high-stakes domains due to unquantified uncertainty. Conformal
  prediction (CP) offers statistical coverage guarantees, but existing methods often
  produce overly conservative prediction intervals that fail to account for graph
  heteroscedasticity and structural biases. While residual reweighting CP variants
  address some of these limitations, they neglect graph topology, cluster-specific
  uncertainties, and risk data leakage by reusing training sets. To address these
  issues, we propose Residual Reweighted GNN (RR-GNN), a framework designed to generate
  minimal prediction sets with provable marginal coverage guarantees. RR-GNN introduces
  three major innovations to enhance prediction performance. First, it employs Graph-Structured
  Mondrian CP to partition nodes or edges into communities based on topological features,
  ensuring cluster-conditional coverage that reflects heterogeneity. Second, it uses
  Residual-Adaptive Nonconformity Scores by training a secondary GNN on a held-out
  calibration set to estimate task-specific residuals, dynamically adjusting prediction
  intervals according to node or edge uncertainty. Third, it adopts a Cross-Training
  Protocol, which alternates the optimization of the primary GNN and the residual
  predictor to prevent information leakage while maintaining graph dependencies. We
  validate RR-GNN on 15 real-world graphs across diverse tasks, including node classification,
  regression, and edge weight prediction. Compared to CP baselines, RR-GNN achieves
  improved efficiency over state-of-the-art methods, with no loss of coverage.
openreview: 4dVMB0KBvR
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang25g
month: 0
tex_title: Residual Reweighted Conformal Prediction for Graph Neural Networks
firstpage: 4982
lastpage: 4999
page: 4982-4999
order: 4982
cycles: false
bibtex_author: Zhang, Zheng and Bao, Jie and Zhou, Zhixin and colombo, nicolo and
  Cheng, Lixin and Luo, Rui
author:
- given: Zheng
  family: Zhang
- given: Jie
  family: Bao
- given: Zhixin
  family: Zhou
- given: nicolo
  family: colombo
- given: Lixin
  family: Cheng
- given: Rui
  family: Luo
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/zhang25g/zhang25g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
