---
title: Statistical Significance of Feature Importance Rankings
abstract: Feature importance scores are ubiquitous tools for understanding the predictions
  of machine learning models. However, many popular attribution methods suffer from
  high instability due to random sampling. Leveraging novel ideas from hypothesis
  testing, we devise techniques that ensure the most important features are correct
  with high-probability guarantees. These are capable of assessing both the set of
  $K$ top-ranked features as well as the order of its elements. Given local or global
  importance scores, we demonstrate how to retrospectively verify the stability of
  the highest ranks. We then introduce two efficient sampling algorithms that identify
  the $K$ most important features, perhaps in order, with probability at least $1-\alpha$.
  The theoretical justification for these procedures is validated empirically on SHAP
  and LIME.
software: https://github.com/jeremy-goldwasser/feature-rankings
openreview: 32BLljqMbd
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: goldwasser25a
month: 0
tex_title: Statistical Significance of Feature Importance Rankings
firstpage: 1476
lastpage: 1496
page: 1476-1496
order: 1476
cycles: false
bibtex_author: Goldwasser, Jeremy and Hooker, Giles
author:
- given: Jeremy
  family: Goldwasser
- given: Giles
  family: Hooker
date: 2025-07-11
address:
container-title: Proceedings of the Forty-first Conference on Uncertainty in Artificial
  Intelligence
volume: '286'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v286/main/assets/goldwasser25a/goldwasser25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
